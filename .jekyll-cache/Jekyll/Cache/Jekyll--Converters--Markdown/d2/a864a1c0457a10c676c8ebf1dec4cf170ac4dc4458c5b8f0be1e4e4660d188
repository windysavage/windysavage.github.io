I"€<h2 id="å‰è¨€">å‰è¨€</h2>
<p>å¯«é€™ç¯‡æ–‡ç« çš„ä¸»è¦ç›®çš„æ˜¯æ•´ç†ä¹‹å‰æ›¾ç¶“åƒåŠ éçš„ç«¶è³½ï¼Œ2019æ™‚æˆ‘å‰›æ¥è§¸Deep learningä¸ä¹…ï¼Œé‚£æ™‚å› ç‚ºèª²ç¨‹è¦æ±‚æ‰€ä»¥åƒåŠ äº†AI Cup 2019çš„è«–æ–‡æ¨™è¨»ç«¶è³½ã€‚ç¾åœ¨å›é ­çœ‹èµ·ä¾†ï¼Œç•¶åˆçš„ç¨‹å¼ç¢¼èˆ‡æƒ³æ³•å¯¦åœ¨æ˜¯ä¸å¤ åš´è¬¹èˆ‡ç´°ç·»ï¼Œé€£æœ€åŸºæœ¬å¾—ç‰ˆæœ¬ã€ç’°å¢ƒæ§ç®¡éƒ½æ²’åšå“ˆå“ˆã€‚æ‰€ä»¥é€™ç¯‡æ–‡ç« å…§å®¹ä¸¦ä¸æœƒå¾ˆå°ˆæ¥­ï¼Œç•¢ç«Ÿç•¶æ™‚çš„æˆ‘ä¹Ÿæ‰å‰›æ¥è§¸ä¸ä¹…è€Œå·²ã€‚</p>

<h2 id="ç«¶è³½èªªæ˜">ç«¶è³½èªªæ˜</h2>
<p>é€™å€‹ç«¶è³½çš„ç›®çš„æ˜¯ï¼Œçµ¦å®šä¸€å€‹è«–æ–‡æ‘˜è¦(Abstract)ï¼Œä½ å¿…é ˆè¦å»ºç«‹ä¸€å€‹æ¨¡å‹åˆ¤æ–·è©²æ‘˜è¦ä¸­çš„æ¯ä¸€å€‹å¥å­æ˜¯å±¬æ–¼å“ªç¨®å¯«æ³•(background, method, resultâ€¦ç­‰ç­‰)ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæ¯ä¸€å€‹å¥å­çš„labelä¸ä¸€å®šåªæœ‰ä¸€å€‹ï¼Œä¹Ÿå°±æ˜¯èªªå¯èƒ½æœƒæœ‰ä¸€äº›å¥å­åŒæ™‚å±¬æ–¼background/methodé€™å…©ç¨®å¯«æ³•ä¹‹é¡çš„ã€‚é€™å°±æ˜¯ç•¶åˆçš„æˆ‘èªç‚ºæ¯”è¼ƒæœ‰æŒ‘æˆ°æ€§çš„åœ°æ–¹ï¼Œå› ç‚ºé€šå¸¸æˆ‘å€‘åšclassification problemçš„æ™‚å€™ï¼Œæ¯å€‹\(x\)éƒ½åªæœƒå°æ‡‰ä¸€å€‹label \(y\)ã€‚æ›´è©³ç´°çš„ç«¶è³½èªªæ˜å¯ä»¥åˆ°<a href="https://tbrain.trendmicro.com.tw/Competitions/Details/8">é€™è£¡</a>çœ‹</p>

<h2 id="è§£é¡Œæ€è€ƒ">è§£é¡Œæ€è€ƒ</h2>
<p>ç¾åœ¨é–‹å§‹reviewæˆ‘ç•¶åˆçš„è§£é¡Œéç¨‹ã€‚</p>
<ol>
  <li>
    <p>å› ç‚ºé€™å€‹ä»»å‹™æ˜¯NLPç›¸é—œï¼Œæ•…å¾ˆç›´æ¥çš„æˆ‘ä¸€é–‹å§‹ä»¥è³‡æ–™æ¸…ç†+RNNç³»åˆ—æ¨¡å‹ä¾†è™•ç†ã€‚é¦–å…ˆæˆ‘å¯ä»¥å°‡ä¸å¿…è¦çš„é›œè¨Šå»é™¤ï¼Œä»¥åŠå°‡ä¸€äº›å¯ä»¥æ•´åˆæˆä¸€é¡çš„è©å½™ä»£æ›æˆåˆ¥çš„token(åƒæ˜¯ç¾åœ‹ã€ä¸­åœ‹ç­‰ç­‰éƒ½å¯ä»¥æ˜¯<b>COUNTRY</b>é€™å€‹token)ã€‚è‡³æ–¼æ¨¡å‹ï¼Œæˆ‘ä¸€é–‹å§‹ä½¿ç”¨çš„æ˜¯LSTMï¼Œä½†å…¶å¯¦æ•ˆæœä¸¦æ²’æœ‰å¾ˆç†æƒ³ã€‚</p>
  </li>
  <li>
    <p>æ¥ä¸‹ä¾†ï¼Œæˆ‘è¦ºå¾—å¯ä»¥åˆ©ç”¨æ›´å¼·çš„æ¨¡å‹å»åšlanguage modelingï¼Œæ‰€ä»¥ç›´æ¥ä½¿ç”¨ç•¶æ™‚å¾ˆå¼·å¤§çš„BERTï¼Œè€Œä¸”<a href="https://tfhub.dev/">tensorflow hub</a>å¾ˆä½›å¿ƒåœ°æœ‰æä¾›å„ç¨®ä»–å€‘å·²ç¶“pre-trainéçš„æ¨¡å‹ï¼Œæˆ‘åªè¦æŒ‘è‡ªå·±éœ€è¦çš„å³å¯ã€‚é™¤æ­¤ä¹‹å¤–ï¼Œå› ç‚ºBERTåœ¨è™•ç†inputçš„æ™‚å€™å·²ç¶“æœ‰æŸç¨®preprocessingçš„æ•ˆæœï¼Œæ‰€ä»¥æˆ‘åœ¨é€™æ™‚å€™é¸æ“‡å…ˆä¸åšä»»ä½•å‰è™•ç†ï¼Œè®“å­å½ˆé£›ä¸€æœƒå…’ï¼Œè©¦è©¦çœ‹BERTçš„å¯¦åŠ›</p>
  </li>
</ol>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="c1"># å¾tensorflow hubæ’ˆæˆ‘éœ€è¦çš„æ¨¡å‹</span>
<span class="n">bert_layer</span> <span class="o">=</span> <span class="n">hub</span><span class="o">.</span><span class="no">KerasLayer</span><span class="p">(</span><span class="s2">"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1"</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="no">True</span><span class="p">)</span>
<span class="n">vocab_file</span> <span class="o">=</span> <span class="n">bert_layer</span><span class="p">.</span><span class="nf">resolved_object</span><span class="p">.</span><span class="nf">vocab_file</span><span class="p">.</span><span class="nf">asset_path</span><span class="p">.</span><span class="nf">numpy</span><span class="p">()</span>
<span class="n">do_lower_case</span> <span class="o">=</span> <span class="n">bert_layer</span><span class="p">.</span><span class="nf">resolved_object</span><span class="p">.</span><span class="nf">do_lower_case</span><span class="p">.</span><span class="nf">numpy</span><span class="p">()</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">bert_tokenization</span><span class="o">.</span><span class="no">FullTokenizer</span><span class="p">(</span><span class="n">vocab_file</span><span class="p">,</span> <span class="n">do_lower_case</span><span class="p">)</span></code></pre></figure>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="c1"># é–‹å§‹å°‡input dataè½‰æ›æˆBERTçœ‹å¾—æ‡‚çš„å½¢å¼</span>
<span class="k">def</span> <span class="nf">get_masks</span><span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="n">max_seq_length</span><span class="p">):</span>
    <span class="s2">"""Mask for padding"""</span>
    <span class="k">if</span> <span class="n">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span><span class="o">&gt;</span><span class="ss">max_seq_length:
        </span><span class="k">raise</span> <span class="no">IndexError</span><span class="p">(</span><span class="s2">"Token length more than max seq length!"</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">max_seq_length</span> <span class="o">-</span> <span class="n">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">get_segments</span><span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="n">max_seq_length</span><span class="p">):</span>
    <span class="s2">"""Segments: 0 for the first sequence, 1 for the second"""</span>
    <span class="k">if</span> <span class="n">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span><span class="o">&gt;</span><span class="ss">max_seq_length:
        </span><span class="k">raise</span> <span class="no">IndexError</span><span class="p">(</span><span class="s2">"Token length more than max seq length!"</span><span class="p">)</span>
    <span class="n">segments</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">current_segment_id</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">token</span> <span class="k">in</span> <span class="ss">tokens:
        </span><span class="n">segments</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">current_segment_id</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">token</span> <span class="o">==</span> <span class="s2">"[SEP]"</span><span class="p">:</span>
            <span class="n">current_segment_id</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">segments</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">max_seq_length</span> <span class="o">-</span> <span class="n">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">get_ids</span><span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">max_seq_length</span><span class="p">):</span>
    <span class="s2">"""Token ids from Tokenizer vocab"""</span>
    <span class="n">token_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="nf">convert_tokens_to_ids</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
    <span class="n">input_ids</span> <span class="o">=</span> <span class="n">token_ids</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">max_seq_length</span><span class="o">-</span><span class="n">len</span><span class="p">(</span><span class="n">token_ids</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">input_ids</span></code></pre></figure>

:ET